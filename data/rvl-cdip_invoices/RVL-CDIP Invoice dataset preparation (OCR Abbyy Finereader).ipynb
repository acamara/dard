{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd199a27",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.981 · TFM Àrea 4 · NLP & Text Mining</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2022 · Màster universitari en Ciència de dades (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicació</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "<div class=\"row\" style=\"padding-top: 50px;\">\n",
    "    <div class=\"row\" style=\"background: #494949;padding: 10px 20px; color: #FFF\">\n",
    "        <div class=\"col-md-12\">\n",
    "            <div style=\"text-align:left;\"><b>Estudiant:</b> Albert Cámara Viñals</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "# RVL-CDIP Invoice dataset preparation for Label Studio (OCR Abbyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba12f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xml.etree import ElementTree as ET\n",
    "from uuid import uuid4\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd =r'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a7ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to mask text\n",
    "def mask_content(text):\n",
    "    masked_alphabetic = re.sub(r'[A-Za-zÀ-ÖØ-öø-ÿ]', r'A', text)\n",
    "    masked_digits = re.sub(r'\\d', r'N', masked_alphabetic)\n",
    "    masked_text = re.sub(r'\\W', r'S', masked_digits)\n",
    "    return masked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b709a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some functions\n",
    "\n",
    "ns = {'pagecontent': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "\n",
    "# Function to read PAGE-XML file and convert to PANDAS dataframe\n",
    "def process_page_xml_file(filename):\n",
    "    document = ET.parse(filename).getroot()\n",
    "    #ET.dump(document)\n",
    "    \n",
    "    # dictionary \n",
    "    invoice = {} \n",
    "    \n",
    "    pages = document.findall('pagecontent:Page', ns)\n",
    "    \n",
    "    num_pages = len(pages)\n",
    "    num_word = 0\n",
    "        \n",
    "    for idx_page, page in enumerate(pages):  \n",
    "        #ET.dump(page)\n",
    "        image_filename = page.get('imageFilename')\n",
    "        page_width = page.get('imageWidth')\n",
    "        page_height = page.get('imageHeight')\n",
    "                \n",
    "        textregions = page.findall('pagecontent:TextRegion', ns)\n",
    "        \n",
    "        for textregion in textregions:\n",
    "            textlines = textregion.findall('pagecontent:TextLine', ns)\n",
    "            \n",
    "            for textline in textlines:\n",
    "                \n",
    "                words = textline.findall('pagecontent:Word', ns)\n",
    "\n",
    "                for word in words:\n",
    "                    coords = word.find('pagecontent:Coords', ns).get('points')\n",
    "                    textequiv = word.find('pagecontent:TextEquiv', ns)\n",
    "                    conf = textequiv.get('conf')\n",
    "                    unicode = textequiv.find('pagecontent:Unicode', ns)\n",
    "                                                    \n",
    "                    invoice[num_word] = {} \n",
    "                \n",
    "                    points = coords.split()\n",
    "                    col =  int(points[0].split(',')[0])\n",
    "                    row = int(points[0].split(',')[1])\n",
    "                    width = int(points[2].split(',')[0]) - int(points[0].split(',')[0])\n",
    "                    height = int(points[2].split(',')[1]) - int(points[0].split(',')[1])\n",
    "                    content = unicode.text\n",
    "                    \n",
    "                    invoice[num_word]['src'] = image_filename\n",
    "                    invoice[num_word]['num_pages'] = num_pages\n",
    "                    invoice[num_word]['page_id'] = idx_page\n",
    "                    invoice[num_word]['page_width'] = int(page_width)\n",
    "                    invoice[num_word]['page_height'] = int(page_height)\n",
    "                    \n",
    "                    invoice[num_word]['col'] = col\n",
    "                    invoice[num_word]['row'] = row\n",
    "                    invoice[num_word]['width'] = width\n",
    "                    invoice[num_word]['height'] = height\n",
    "                    invoice[num_word]['x1'] = col\n",
    "                    invoice[num_word]['y1'] = row\n",
    "                    invoice[num_word]['x2'] = col + width\n",
    "                    invoice[num_word]['y2'] = row\n",
    "                    invoice[num_word]['x3'] = col + width\n",
    "                    invoice[num_word]['y3'] = row + height\n",
    "                    invoice[num_word]['x4'] = col \n",
    "                    invoice[num_word]['y4'] = row + height\n",
    "                    \n",
    "                    invoice[num_word]['contents'] = content\n",
    "                    invoice[num_word]['contents_masked'] = mask_content(content)\n",
    "                    invoice[num_word]['confidence'] = round(float(conf), 2)\n",
    "                    \n",
    "                    invoice[num_word]['correctclass'] = 'undefined'\n",
    "                    invoice[num_word]['tag'] = 'OTHER'\n",
    "                    invoice[num_word]['description'] = 'OTHER'\n",
    "                    num_word = num_word + 1\n",
    "\n",
    "    # Create pandas dataframe from invoice object\n",
    "    df = pd.DataFrame(invoice).transpose()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff28f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_url(filepath):\n",
    "    \"\"\"\n",
    "    Label Studio requires image URLs, so this defines the mapping from filesystem to URLs\n",
    "    if you use ./serve_local_files.sh <my-images-dir>, the image URLs are localhost:8081/filename.png\n",
    "    Otherwise you can build links like /data/upload/filename.png to refer to the files\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    #return f'http://localhost:8081/{filename}'\n",
    "    return f'/data/local-files/?d=images/{filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ed35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_studio_annotations(filename, data):\n",
    "    results = []\n",
    "    all_scores = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        region_id = str(uuid4())[:10]\n",
    "        bbox = {\n",
    "                'x': 100 * row['x1']/row['page_width'],\n",
    "                'y': 100 * row['y1']/row['page_height'],\n",
    "                'width': 100 * row['width']/row['page_width'],\n",
    "                'height': 100 * row['height']/row['page_height'],\n",
    "                'rotation': 0\n",
    "        }\n",
    "        \n",
    "        bbox_result = {\n",
    "            'id': region_id, \n",
    "            'from_name': 'bbox', \n",
    "            'to_name': 'image', \n",
    "            'type': 'rectangle', \n",
    "            'value': bbox\n",
    "        }\n",
    "        \n",
    "        transcription_result = {\n",
    "            'id': region_id, \n",
    "            'from_name': 'transcription', \n",
    "            'to_name': 'image', \n",
    "            'type': 'textarea', \n",
    "            'value': dict(**bbox, text=[row['contents']])\n",
    "        }\n",
    "        \n",
    "        label_result = {\n",
    "            'id': region_id, \n",
    "            'from_name': 'label', \n",
    "            'to_name': 'image', \n",
    "            'type': 'labels', \n",
    "            'value': dict(**bbox, labels=[row['tag']])\n",
    "        }\n",
    "        \n",
    "        results.extend([bbox_result, transcription_result, label_result])\n",
    "        all_scores.append(row['confidence']),\n",
    "        \n",
    "    return {\n",
    "        'data': {\n",
    "           'ocr': create_image_url(filename)\n",
    "        },\n",
    "        'predictions': [{\n",
    "            'result': results,\n",
    "            'score': sum(all_scores) / len(all_scores) if all_scores else 0\n",
    "        }]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "047121e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files:  519\n"
     ]
    }
   ],
   "source": [
    "# Define data directories\n",
    "data_dir = 'data/original/pageXML_file_ocr/'\n",
    "data_transformed_dir = 'data/transformed/'\n",
    "\n",
    "# Get list of PAGE-XML files\n",
    "page_xml_files = glob.glob(data_dir + \"*.xml\")\n",
    "\n",
    "# Show number of files\n",
    "num_page_xml_files = len(page_xml_files)\n",
    "print('Number of files: ', num_page_xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e7df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/519\n",
      "Processing 2/519\n",
      "Processing 3/519\n",
      "Processing 4/519\n",
      "Processing 5/519\n",
      "Processing 6/519\n",
      "Processing 7/519\n",
      "Processing 8/519\n",
      "Processing 9/519\n",
      "Processing 10/519\n",
      "Processing 11/519\n",
      "Processing 12/519\n",
      "Processing 13/519\n",
      "Processing 14/519\n",
      "Processing 15/519\n",
      "Processing 16/519\n",
      "Processing 17/519\n",
      "Processing 18/519\n",
      "Processing 19/519\n",
      "Processing 20/519\n",
      "Processing 21/519\n",
      "Processing 22/519\n",
      "Processing 23/519\n",
      "Processing 24/519\n",
      "Processing 25/519\n",
      "Processing 26/519\n",
      "Processing 27/519\n",
      "Processing 28/519\n",
      "Processing 29/519\n",
      "Processing 30/519\n",
      "Processing 31/519\n",
      "Processing 32/519\n",
      "Processing 33/519\n",
      "Processing 34/519\n",
      "Processing 35/519\n",
      "Processing 36/519\n",
      "Processing 37/519\n",
      "Processing 38/519\n",
      "Processing 39/519\n",
      "Processing 40/519\n",
      "Processing 41/519\n",
      "Processing 42/519\n",
      "Processing 43/519\n",
      "Processing 44/519\n",
      "Processing 45/519\n",
      "Processing 46/519\n",
      "Processing 47/519\n",
      "Processing 48/519\n",
      "Processing 49/519\n",
      "Processing 50/519\n",
      "Processing 51/519\n",
      "Processing 52/519\n",
      "Processing 53/519\n",
      "Processing 54/519\n",
      "Processing 55/519\n",
      "Processing 56/519\n",
      "Processing 57/519\n",
      "Processing 58/519\n",
      "Processing 59/519\n",
      "Processing 60/519\n",
      "Processing 61/519\n",
      "Processing 62/519\n",
      "Processing 63/519\n",
      "Processing 64/519\n",
      "Processing 65/519\n",
      "Processing 66/519\n",
      "Processing 67/519\n",
      "Processing 68/519\n",
      "Processing 69/519\n",
      "Processing 70/519\n",
      "Processing 71/519\n",
      "Processing 72/519\n",
      "Processing 73/519\n",
      "Processing 74/519\n",
      "Processing 75/519\n",
      "Processing 76/519\n",
      "Processing 77/519\n",
      "Processing 78/519\n",
      "Processing 79/519\n",
      "Processing 80/519\n",
      "Processing 81/519\n",
      "Processing 82/519\n",
      "Processing 83/519\n",
      "Processing 84/519\n",
      "Processing 85/519\n",
      "Processing 86/519\n",
      "Processing 87/519\n",
      "Processing 88/519\n",
      "Processing 89/519\n",
      "Processing 90/519\n",
      "Processing 91/519\n",
      "Processing 92/519\n",
      "Processing 93/519\n",
      "Processing 94/519\n",
      "Processing 95/519\n",
      "Processing 96/519\n",
      "Processing 97/519\n",
      "Processing 98/519\n",
      "Processing 99/519\n",
      "Processing 100/519\n",
      "Processing 101/519\n",
      "Processing 102/519\n",
      "Processing 103/519\n",
      "Processing 104/519\n",
      "Processing 105/519\n",
      "Processing 106/519\n",
      "Processing 107/519\n",
      "Processing 108/519\n",
      "Processing 109/519\n",
      "Processing 110/519\n",
      "Processing 111/519\n",
      "Processing 112/519\n",
      "Processing 113/519\n",
      "Processing 114/519\n",
      "Processing 115/519\n",
      "Processing 116/519\n",
      "Processing 117/519\n",
      "Processing 118/519\n",
      "Processing 119/519\n",
      "Processing 120/519\n",
      "Processing 121/519\n",
      "Processing 122/519\n",
      "Processing 123/519\n",
      "Processing 124/519\n",
      "Processing 125/519\n",
      "Processing 126/519\n",
      "Processing 127/519\n",
      "Processing 128/519\n",
      "Processing 129/519\n",
      "Processing 130/519\n",
      "Processing 131/519\n",
      "Processing 132/519\n",
      "Processing 133/519\n",
      "Processing 134/519\n",
      "Processing 135/519\n",
      "Processing 136/519\n",
      "Processing 137/519\n",
      "Processing 138/519\n",
      "Processing 139/519\n",
      "Processing 140/519\n",
      "Processing 141/519\n",
      "Processing 142/519\n",
      "Processing 143/519\n",
      "Processing 144/519\n",
      "Processing 145/519\n",
      "Processing 146/519\n",
      "Processing 147/519\n",
      "Processing 148/519\n",
      "Processing 149/519\n",
      "Processing 150/519\n",
      "Processing 151/519\n",
      "Processing 152/519\n",
      "Processing 153/519\n",
      "Processing 154/519\n",
      "Processing 155/519\n",
      "Processing 156/519\n",
      "Processing 157/519\n",
      "Processing 158/519\n",
      "Processing 159/519\n",
      "Processing 160/519\n",
      "Processing 161/519\n",
      "Processing 162/519\n",
      "Processing 163/519\n",
      "Processing 164/519\n",
      "Processing 165/519\n",
      "Processing 166/519\n",
      "Processing 167/519\n",
      "Processing 168/519\n",
      "Processing 169/519\n",
      "Processing 170/519\n",
      "Processing 171/519\n",
      "Processing 172/519\n",
      "Processing 173/519\n",
      "Processing 174/519\n",
      "Processing 175/519\n",
      "Processing 176/519\n",
      "Processing 177/519\n",
      "Processing 178/519\n",
      "Processing 179/519\n",
      "Processing 180/519\n",
      "Processing 181/519\n",
      "Processing 182/519\n",
      "Processing 183/519\n",
      "Processing 184/519\n",
      "Processing 185/519\n",
      "Processing 186/519\n",
      "Processing 187/519\n",
      "Processing 188/519\n",
      "Processing 189/519\n",
      "Processing 190/519\n",
      "Processing 191/519\n",
      "Processing 192/519\n",
      "Processing 193/519\n",
      "Processing 194/519\n",
      "Processing 195/519\n",
      "Processing 196/519\n",
      "Processing 197/519\n",
      "Processing 198/519\n",
      "Processing 199/519\n",
      "Processing 200/519\n",
      "Processing 201/519\n",
      "Processing 202/519\n",
      "Processing 203/519\n",
      "Processing 204/519\n",
      "Processing 205/519\n",
      "Processing 206/519\n",
      "Processing 207/519\n",
      "Processing 208/519\n",
      "Processing 209/519\n",
      "Processing 210/519\n",
      "Processing 211/519\n",
      "Processing 212/519\n",
      "Processing 213/519\n",
      "Processing 214/519\n",
      "Processing 215/519\n",
      "Processing 216/519\n",
      "Processing 217/519\n",
      "Processing 218/519\n",
      "Processing 219/519\n",
      "Processing 220/519\n",
      "Processing 221/519\n",
      "Processing 222/519\n",
      "Processing 223/519\n",
      "Processing 224/519\n",
      "Processing 225/519\n",
      "Processing 226/519\n",
      "Processing 227/519\n",
      "Processing 228/519\n",
      "Processing 229/519\n",
      "Processing 230/519\n",
      "Processing 231/519\n",
      "Processing 232/519\n",
      "Processing 233/519\n",
      "Processing 234/519\n",
      "Processing 235/519\n",
      "Processing 236/519\n",
      "Processing 237/519\n",
      "Processing 238/519\n",
      "Processing 239/519\n",
      "Processing 240/519\n",
      "Processing 241/519\n",
      "Processing 242/519\n",
      "Processing 243/519\n",
      "Processing 244/519\n",
      "Processing 245/519\n",
      "Processing 246/519\n",
      "Processing 247/519\n",
      "Processing 248/519\n",
      "Processing 249/519\n",
      "Processing 250/519\n",
      "Processing 251/519\n",
      "Processing 252/519\n",
      "Processing 253/519\n",
      "Processing 254/519\n",
      "Processing 255/519\n",
      "Processing 256/519\n",
      "Processing 257/519\n",
      "Processing 258/519\n",
      "Processing 259/519\n",
      "Processing 260/519\n",
      "Processing 261/519\n",
      "Processing 262/519\n",
      "Processing 263/519\n",
      "Processing 264/519\n",
      "Processing 265/519\n",
      "Processing 266/519\n",
      "Processing 267/519\n",
      "Processing 268/519\n",
      "Processing 269/519\n",
      "Processing 270/519\n",
      "Processing 271/519\n",
      "Processing 272/519\n",
      "Processing 273/519\n",
      "Processing 274/519\n",
      "Processing 275/519\n",
      "Processing 276/519\n",
      "Processing 277/519\n",
      "Processing 278/519\n",
      "Processing 279/519\n",
      "Processing 280/519\n",
      "Processing 281/519\n",
      "Processing 282/519\n",
      "Processing 283/519\n",
      "Processing 284/519\n",
      "Processing 285/519\n",
      "Processing 286/519\n",
      "Processing 287/519\n",
      "Processing 288/519\n",
      "Processing 289/519\n",
      "Processing 290/519\n",
      "Processing 291/519\n",
      "Processing 292/519\n",
      "Processing 293/519\n",
      "Processing 294/519\n",
      "Processing 295/519\n",
      "Processing 296/519\n",
      "Processing 297/519\n",
      "Processing 298/519\n",
      "Processing 299/519\n",
      "Processing 300/519\n",
      "Processing 301/519\n",
      "Processing 302/519\n",
      "Processing 303/519\n",
      "Processing 304/519\n",
      "Processing 305/519\n",
      "Processing 306/519\n",
      "Processing 307/519\n",
      "Processing 308/519\n",
      "Processing 309/519\n",
      "Processing 310/519\n",
      "Processing 311/519\n",
      "Processing 312/519\n",
      "Processing 313/519\n",
      "Processing 314/519\n",
      "Processing 315/519\n",
      "Processing 316/519\n",
      "Processing 317/519\n",
      "Processing 318/519\n",
      "Processing 319/519\n",
      "Processing 320/519\n",
      "Processing 321/519\n",
      "Processing 322/519\n",
      "Processing 323/519\n",
      "Processing 324/519\n",
      "Processing 325/519\n",
      "Processing 326/519\n",
      "Processing 327/519\n",
      "Processing 328/519\n",
      "Processing 329/519\n",
      "Processing 330/519\n",
      "Processing 331/519\n",
      "Processing 332/519\n",
      "Processing 333/519\n",
      "Processing 334/519\n",
      "Processing 335/519\n",
      "Processing 336/519\n",
      "Processing 337/519\n",
      "Processing 338/519\n",
      "Processing 339/519\n",
      "Processing 340/519\n",
      "Processing 341/519\n",
      "Processing 342/519\n",
      "Processing 343/519\n",
      "Processing 344/519\n",
      "Processing 345/519\n",
      "Processing 346/519\n",
      "Processing 347/519\n",
      "Processing 348/519\n",
      "Processing 349/519\n",
      "Processing 350/519\n",
      "Processing 351/519\n",
      "Processing 352/519\n",
      "Processing 353/519\n",
      "Processing 354/519\n",
      "Processing 355/519\n",
      "Processing 356/519\n",
      "Processing 357/519\n",
      "Processing 358/519\n",
      "Processing 359/519\n",
      "Processing 360/519\n",
      "Processing 361/519\n",
      "Processing 362/519\n",
      "Processing 363/519\n",
      "Processing 364/519\n",
      "Processing 365/519\n",
      "Processing 366/519\n",
      "Processing 367/519\n",
      "Processing 368/519\n",
      "Processing 369/519\n",
      "Processing 370/519\n",
      "Processing 371/519\n",
      "Processing 372/519\n",
      "Processing 373/519\n",
      "Processing 374/519\n",
      "Processing 375/519\n",
      "Processing 376/519\n",
      "Processing 377/519\n",
      "Processing 378/519\n",
      "Processing 379/519\n",
      "Processing 380/519\n",
      "Processing 381/519\n",
      "Processing 382/519\n",
      "Processing 383/519\n",
      "Processing 384/519\n",
      "Processing 385/519\n",
      "Processing 386/519\n",
      "Processing 387/519\n",
      "Processing 388/519\n",
      "Processing 389/519\n",
      "Processing 390/519\n",
      "Processing 391/519\n",
      "Processing 392/519\n",
      "Processing 393/519\n",
      "Processing 394/519\n",
      "Processing 395/519\n",
      "Processing 396/519\n",
      "Processing 397/519\n",
      "Processing 398/519\n",
      "Processing 399/519\n",
      "Processing 400/519\n",
      "Processing 401/519\n",
      "Processing 402/519\n",
      "Processing 403/519\n",
      "Processing 404/519\n",
      "Processing 405/519\n",
      "Processing 406/519\n",
      "Processing 407/519\n",
      "Processing 408/519\n",
      "Processing 409/519\n",
      "Processing 410/519\n",
      "Processing 411/519\n",
      "Processing 412/519\n",
      "Processing 413/519\n",
      "Processing 414/519\n",
      "Processing 415/519\n",
      "Processing 416/519\n",
      "Processing 417/519\n",
      "Processing 418/519\n",
      "Processing 419/519\n",
      "Processing 420/519\n",
      "Processing 421/519\n",
      "Processing 422/519\n",
      "Processing 423/519\n",
      "Processing 424/519\n",
      "Processing 425/519\n",
      "Processing 426/519\n",
      "Processing 427/519\n",
      "Processing 428/519\n",
      "Processing 429/519\n",
      "Processing 430/519\n",
      "Processing 431/519\n",
      "Processing 432/519\n",
      "Processing 433/519\n",
      "Processing 434/519\n",
      "Processing 435/519\n",
      "Processing 436/519\n",
      "Processing 437/519\n",
      "Processing 438/519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 439/519\n",
      "Processing 440/519\n",
      "Processing 441/519\n",
      "Processing 442/519\n",
      "Processing 443/519\n",
      "Processing 444/519\n",
      "Processing 445/519\n",
      "Processing 446/519\n",
      "Processing 447/519\n",
      "Processing 448/519\n",
      "Processing 449/519\n",
      "Processing 450/519\n",
      "Processing 451/519\n",
      "Processing 452/519\n",
      "Processing 453/519\n",
      "Processing 454/519\n",
      "Processing 455/519\n",
      "Processing 456/519\n",
      "Processing 457/519\n",
      "Processing 458/519\n",
      "Processing 459/519\n",
      "Processing 460/519\n",
      "Processing 461/519\n",
      "Processing 462/519\n",
      "Processing 463/519\n",
      "Processing 464/519\n",
      "Processing 465/519\n",
      "Processing 466/519\n",
      "Processing 467/519\n",
      "Processing 468/519\n",
      "Processing 469/519\n",
      "Processing 470/519\n",
      "Processing 471/519\n",
      "Processing 472/519\n",
      "Processing 473/519\n",
      "Processing 474/519\n",
      "Processing 475/519\n",
      "Processing 476/519\n",
      "Processing 477/519\n",
      "Processing 478/519\n",
      "Processing 479/519\n",
      "Processing 480/519\n",
      "Processing 481/519\n",
      "Processing 482/519\n",
      "Processing 483/519\n",
      "Processing 484/519\n",
      "Processing 485/519\n",
      "Processing 486/519\n",
      "Processing 487/519\n",
      "Processing 488/519\n",
      "Processing 489/519\n",
      "Processing 490/519\n",
      "Processing 491/519\n",
      "Processing 492/519\n",
      "Processing 493/519\n",
      "Processing 494/519\n",
      "Processing 495/519\n",
      "Processing 496/519\n",
      "Processing 497/519\n",
      "Processing 498/519\n",
      "Processing 499/519\n",
      "Processing 500/519\n",
      "Processing 501/519\n",
      "Processing 502/519\n",
      "Processing 503/519\n",
      "Processing 504/519\n",
      "Processing 505/519\n",
      "Processing 506/519\n",
      "Processing 507/519\n",
      "Processing 508/519\n",
      "Processing 509/519\n",
      "Processing 510/519\n",
      "Processing 511/519\n",
      "Processing 512/519\n",
      "Processing 513/519\n",
      "Processing 514/519\n",
      "Processing 515/519\n",
      "Processing 516/519\n",
      "Processing 517/519\n",
      "Processing 518/519\n",
      "Processing 519/519\n"
     ]
    }
   ],
   "source": [
    "tasks =[]\n",
    "\n",
    "# Loop all files and process (convert to dataframe and label studio preannotation)\n",
    "for idx, page_xml_file in enumerate(page_xml_files):\n",
    "    print('Processing ' + str(idx + 1) +'/' + str(num_page_xml_files))\n",
    "    # Get filepath\n",
    "    base = os.path.basename(page_xml_file)\n",
    "    \n",
    "    # Get basename\n",
    "    basename = os.path.splitext(base)[0]\n",
    "        \n",
    "    # Read PAGE-XML into pandas dataframe\n",
    "    df = process_page_xml_file(page_xml_file)\n",
    "\n",
    "    # Sort dataframe by top row and top column (0,0) (left, top)\n",
    "    df.sort_values(by=['row', 'col'], inplace=True, ascending = [True, True])\n",
    "\n",
    "    # Save dataframe\n",
    "    df.to_csv(data_transformed_dir + basename + '.csv', index = False, sep=';')\n",
    "\n",
    "    labeled = create_label_studio_annotations(basename[:-4] + '.png', df)\n",
    "\n",
    "    tasks.append(labeled)\n",
    "    \n",
    "# Create and a file to import into Label Studio\n",
    "with open(data_transformed_dir + 'preannotated_ocr_abbyy_tasks.json', mode='w') as f:\n",
    "    json.dump(tasks, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec2aed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
